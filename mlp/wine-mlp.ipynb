{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import","metadata":{"execution":{"iopub.status.busy":"2025-11-20T06:40:01.682886Z","iopub.execute_input":"2025-11-20T06:40:01.684313Z","iopub.status.idle":"2025-11-20T06:40:01.689452Z","shell.execute_reply.started":"2025-11-20T06:40:01.684266Z","shell.execute_reply":"2025-11-20T06:40:01.688023Z"}}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.datasets import load_wine\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-20T08:05:13.297787Z","iopub.execute_input":"2025-11-20T08:05:13.298152Z","iopub.status.idle":"2025-11-20T08:05:13.304798Z","shell.execute_reply.started":"2025-11-20T08:05:13.298130Z","shell.execute_reply":"2025-11-20T08:05:13.303788Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1. データ読込","metadata":{}},{"cell_type":"code","source":"# ワインデータセットをロード\nwine = load_wine()\nX = wine.data\ny = wine.target\n\n# データを訓練用とテスト用に分割 (層化抽出)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y,\n    test_size=0.2, # 20%をテストデータに\n    random_state=42, # 乱数シード固定\n    stratify=y # ターゲット（ワインの３クラス）が均等になるようsplit\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T08:05:13.316109Z","iopub.execute_input":"2025-11-20T08:05:13.316426Z","iopub.status.idle":"2025-11-20T08:05:13.326386Z","shell.execute_reply.started":"2025-11-20T08:05:13.316404Z","shell.execute_reply":"2025-11-20T08:05:13.325229Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 参考 データの意味\n- `X` - 178行 × 13列\n    - `alcohol` - アルコール度数\n    - `malic_acid` - リンゴ酸含有量\n    - `ash` - 灰分\n    - `alcalinity_of_ash` - 灰分のアルカリ度\n    - `magnesium` - マグネシウム含有量\n    - `total_phenols` - 総フェノール含有量\n    - `flavanoids` - フラバノイド含有量\n    - `nonflavanoid_phenols` - 非フラバノイドフェノール含有量\n    - `proanthocyanins` - プロアントシアニン含有量\n    - `color_intensity` - 色の濃さ\n    - `hue` - 色相\n    - `od280/od315_of_diluted_wines` - 希釈ワインの280nm/315nmでの吸光度比\n    - `proline` -プロリン含有量\n- `y` - ワインの等級3種類のクラスラベル、これを当てます","metadata":{}},{"cell_type":"code","source":"# PyTorchのテンソルに変換\n# 特徴量はfloat型、ラベルはlong型（分類タスクの損失関数に必要）\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32)\ny_train_tensor = torch.tensor(y_train, dtype=torch.long)\nX_test_tensor = torch.tensor(X_test, dtype=torch.float32)\ny_test_tensor = torch.tensor(y_test, dtype=torch.long)\n\n# DataLoaderを作成\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T08:05:13.586316Z","iopub.execute_input":"2025-11-20T08:05:13.586689Z","iopub.status.idle":"2025-11-20T08:05:13.604935Z","shell.execute_reply.started":"2025-11-20T08:05:13.586663Z","shell.execute_reply":"2025-11-20T08:05:13.603748Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**コラム：torch.Tensorだと何が嬉しいのか**\n1. `X_train_tensor.to('cuda')` で GPUのサポートを受けられる\n2. `requires_grad=True` で自動微分ができる","metadata":{}},{"cell_type":"markdown","source":"# 2. モデルの定義","metadata":{}},{"cell_type":"code","source":"class SimpleMLP(nn.Module):\n    def __init__(self, input_size, num_classes):\n        super(SimpleMLP, self).__init__()\n        # MLP層\n        self.layer1 = nn.Linear(input_size, 64)\n        self.relu = nn.ReLU()\n        self.layer2 = nn.Linear(64, num_classes) # num_classesは3 (3品種)\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.relu(x)\n        x = self.layer2(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T08:19:27.976167Z","iopub.execute_input":"2025-11-20T08:19:27.977279Z","iopub.status.idle":"2025-11-20T08:19:27.983684Z","shell.execute_reply.started":"2025-11-20T08:19:27.977237Z","shell.execute_reply":"2025-11-20T08:19:27.982580Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# モデルのインスタンス化\n# 入力サイズは13 (ワインの特徴量数)、出力サイズは3 (等級数)\ninput_size = X_train.shape[1] # 13\nnum_classes = len(np.unique(y)) # 3\nmodel = SimpleMLP(input_size, num_classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T08:19:29.561009Z","iopub.execute_input":"2025-11-20T08:19:29.561433Z","iopub.status.idle":"2025-11-20T08:19:29.568843Z","shell.execute_reply.started":"2025-11-20T08:19:29.561406Z","shell.execute_reply":"2025-11-20T08:19:29.567597Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. 学習の設定","metadata":{}},{"cell_type":"code","source":"# 損失関数: CrossEntropyLoss (多クラス分類)\ncriterion = nn.CrossEntropyLoss()\n# 最適化手法: Adam 一般的に高性能な最適化手法\noptimizer = optim.Adam(model.parameters(), lr=0.01)\n# 学習回数\nnum_epochs = 30","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T08:20:54.801870Z","iopub.execute_input":"2025-11-20T08:20:54.803093Z","iopub.status.idle":"2025-11-20T08:20:54.808844Z","shell.execute_reply.started":"2025-11-20T08:20:54.803033Z","shell.execute_reply":"2025-11-20T08:20:54.807722Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. 学習ループ","metadata":{}},{"cell_type":"code","source":"print(\"--- 学習開始 ---\")\nfor epoch in range(num_epochs):\n    model.train() # モデルを訓練モードに設定\n    for inputs, labels in train_loader:\n        # 勾配をゼロにリセット\n        optimizer.zero_grad()\n        \n        # 順伝播\n        outputs = model(inputs)\n        \n        # 損失の計算\n        loss = criterion(outputs, labels)\n        \n        # 逆伝播\n        loss.backward()\n\n        # パラメータの更新\n        optimizer.step()\n\n    # 学習進捗の表示\n    if (epoch + 1) % 10 == 0:\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\nprint(\"--- 学習終了 ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T08:20:45.809184Z","iopub.execute_input":"2025-11-20T08:20:45.809546Z","iopub.status.idle":"2025-11-20T08:20:46.362845Z","shell.execute_reply.started":"2025-11-20T08:20:45.809525Z","shell.execute_reply":"2025-11-20T08:20:46.361659Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 学習した重みパラメータの可視化 最初の層 (layer1)の例\nstate_dict = model.state_dict()\nlayer1_weight = state_dict['layer1.weight']\nlayer1_bias = state_dict['layer1.bias']\n\nprint(\"--- 2. 特定の層の重みとバイアスの内容 ---\")\n\n# 重み（一部表示）\nprint(\"\\n[layer1.weight] (重み W) 最初の5行と5列だけ:\")\nprint(layer1_weight[:5, :5]) \n\n# バイアス（全て表示）\nprint(\"\\n[layer1.bias] (バイアス b):\")\nprint(layer1_bias)\n\n# 形状の確認\nprint(f\"\\nlayer1.weight の形状: {layer1_weight.shape}\")\nprint(f\"layer1.bias の形状: {layer1_bias.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T08:38:26.684417Z","iopub.execute_input":"2025-11-20T08:38:26.684777Z","iopub.status.idle":"2025-11-20T08:38:26.698442Z","shell.execute_reply.started":"2025-11-20T08:38:26.684743Z","shell.execute_reply":"2025-11-20T08:38:26.697219Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. 推論と評価","metadata":{}},{"cell_type":"code","source":"# モデルを評価モードに設定（Dropoutなどの層を無効化）\nmodel.eval()\n\n# テストデータでの推論\nwith torch.no_grad(): # 勾配計算を無効化\n    # 推論（テストデータ全体を一度に）\n    test_outputs = model(X_test_tensor)\n    \n    # 予測クラスを取得\n    # torch.max(test_outputs, 1) は (最大値, インデックス) を返す。インデックスが予測クラス。\n    _, predicted = torch.max(test_outputs.data, 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T08:20:48.150721Z","iopub.execute_input":"2025-11-20T08:20:48.151708Z","iopub.status.idle":"2025-11-20T08:20:48.157752Z","shell.execute_reply.started":"2025-11-20T08:20:48.151676Z","shell.execute_reply":"2025-11-20T08:20:48.156776Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# PyTorchテンソルをNumPy配列に変換\ny_pred = predicted.numpy()\ny_true = y_test_tensor.numpy()\n\n# 正解率の計算\naccuracy = accuracy_score(y_true, y_pred)\n\nprint(\"\\n--- 評価結果 ---\")\nprint(\"施策: ベースライン\")\nprint(f\"テストデータの予測結果: {y_pred}\")\nprint(f\"テストデータの正解率 (Accuracy): {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T08:50:40.741816Z","iopub.execute_input":"2025-11-20T08:50:40.742203Z","iopub.status.idle":"2025-11-20T08:50:40.750789Z","shell.execute_reply.started":"2025-11-20T08:50:40.742178Z","shell.execute_reply":"2025-11-20T08:50:40.749545Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 練習問題\n- みなさんは、AIエンジニアです。正解率90%のワインソムリエAIを作ってください。\n- 精度が上がったら、評価結果をチャットに貼って報告してください。\n\n**チャットのフォーマット**\n```\n--- 評価結果 ---\n施策: XXXXの値をXXXXに変更\nテストデータの予測結果: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\nテストデータの正解率 (Accuracy): 0.3889\n```","metadata":{}},{"cell_type":"markdown","source":"### ヒント\n1. MLPの構造を変えてみましょう\n    1. 層数\n    1. 隠れ層の次元数\n1. ハイパーパラメータを変えてみましょう\n    1. 学習回数（エポック数）\n    1. 学習率\n    1. optimizerの種類\n    1. 損失関数の種類","metadata":{}}]}
